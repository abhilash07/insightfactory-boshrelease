---
name: clientmr
packages:
- git
- java
- scala
- sbt
- spark
- hadoopmr
- python
- sasl
- mesos
- pig
- hive
templates:
  bin/job_properties.sh.erb: bin/job_properties.sh
  bin/setup.sh.erb: bin/setup.sh
  config/hadoop-env.sh.erb: config/hadoop-env.sh
  config/hdfs-site.xml.erb: config/hdfs-site.xml
  config/core-site.xml.erb: config/core-site.xml
  config/hive-env.sh.erb: config/hive-env.sh
  config/hive-site.xml.erb: config/hive-site.xml
  config/hadoop-metrics.properties: config/hadoop-metrics.properties
  config/hadoop-metrics2.properties: config/hadoop-metrics2.properties
  config/capacity-scheduler.xml.erb: config/capacity-scheduler.xml
  config/mapred-site.xml.erb: config/mapred-site.xml
  config/spark-env.sh.erb: config/spark-env.sh
properties:
  spark.master.host:
    description: The Hostname or address of the Spark master
    default: 0.spark-master.default.spark-aws-ec2.bosh
  spark.masters:
    description: List of all Spark Masters
    default: 0.spark-master.default.spark-aws-ec2.bosh:7077
  spark.master.port:
    description: The port to listen on
    default: 7077
  spark.deploy.zookeeper.dir:
    description: The directory in ZooKeeper to store recovery state
    default: /var/vcap/data/tmp
  spark.cluster.name:
    description: The name of the cluster as shown in the Spark admin ui
    default: bosh-spark-cluster
  zookeeper.servers:
    description: "List of all Apache Zookeeper server host IP/hostnames"
  zookeeper.client_port:
    description: "Port at which the clients will connect to Apache Zookeeper"
    default: 2181
  hadoop.namenode.host:
    description: The Hostname or address of the Hadoop Namenode
  hadoop.namenode.port:
    description: The port to listen on
    default: 8020
  hadoop.namenode.safemode_min_datanodes:
    description: Minimum number of data node
    default: 3
  hadoop.namenode.num_dfs_replicas:
    description: Number of dfs replicas
    default: 3
  hadoop.namenode.dfs_name_dir:
    description: dfs name directory
    default: /cache/hadoop/dfs/name
  hadoop.namenode.hadoop_tmp_dir:
    description: hdfs user tmp directory
    default: /var/vcap/data/hadoop/tmp
  hadoop.namenode.dfs_name_dir_root:
    description: dfs root
    default: /var/vcap/data/hadoop
  hadoop.datanode.dfs_data_dir:
    description: dfs data directory
    default: /cache/hdfs/dfs/data
  hadoop.mapreduce.job.tracker:
    description: MapReduce Job Tracker
    default: ""
  hadoop.mapreduce.local.dir:
    description: MapReduce Job Tracker
    default: /var/vcap/data/hadoop/tmp
  hadoop.mapreduce.child.java.opts:
    description: MapReduce Child Java Opts
    default: "-server -Xmx512m -Djava.net.preferIPv4Stack=true"
  hadoop.mapreduce.map.child.java.opts:
    description: MapReduce Map Child Java Opts
    default: "-server -Xmx512m -Djava.net.preferIPv4Stack=true"
  hadoop.mapreduce.reduce.child.java.opts:
    description: MapReduce Child Java Opts
    default: "-server -Xmx1024m -Djava.net.preferIPv4Stack=true"
